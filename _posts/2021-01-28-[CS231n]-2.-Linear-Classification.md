---
layout: post
title:  "[CS231n] 2. Linear Classification"
author: jspark
date: '2021-01-28 16:15:00 +0900'
category: CS231n
use_math: true
---


## 1. Linear Classification(선형 분류)

- CS231n의 [유튜브 강의 내용](https://youtu.be/OoUX-nOEjG0)과 [강의 노트](https://cs231n.github.io/linear-classify/)를 참고하여 작성하였습니다.
- 이 포스트는 CS231n - Lecture2~3 의 내용을 포함합니다.
- 데스크탑이나 노트북의 경우 글꼴 크기를 확대(ctrl + 마우스 스크롤) 하여 보는 것을 추천합니다.
- 파이썬 코드는 글의 내용에 포함되지 않습니다.



### 1-1. Overview

---

- 지난 시간에 배웠던 Image Classificaion을 확장시켜 Neural Network와 Convolution Neural Network를 배우는 Section이다.
- 자세히는<br>**score function**: raw data를 class score로 매핑해주는 function.<br>**loss function**: 모델의 predicted score와 실제 label의 차이를 보여주는 function.<br>**Optimization Problem**: score function의 parameter에 대한 loss function을 최소화 하는것<br>에 대한 내용을 다룬다.



## 2. Parameterized mapping from images to label scores

- **Score function**
  - 이미지들의 픽셀값을 각 클래스들의 점수로 매핑해주는 함수.
  - 이미지 X 가 있고 클래스가 {고양이, 강아지, 배} 3개가 있다고 한다면 score function은<br> 이미지 X를 (4, 6, 2) 와 같이 각 클래스들에 대한 점수로 매핑해준다.
- 앞으로는 강의 교안에서 나오는 예시로 설명하도록 하겠다.

학습 데이터셋 이미지들인

$$
x_i \in R^D
$$

가 있고, 각각이 해당 라벨

$$
y_i
$$

를 갖고 있다고 하자. 여기서

$$
i = 1 \dots N,   y_i \in \{ 1 \dots K \}
$$

이다.

  학습할 데이터 **N** 개가 있고 (각각은 **D** 차원의 벡터이다.), 총 **K** 개의 서로 다른 카테고리(클래스)가 있다.<br>  예를 들어, CIFAR-10 에서는 **N** = 50,000 개의 학습 데이터 이미지들이 있고,<br>  각각은 **D** = 32 x 32 x 3 = 3072 픽셀로 이루어져 있으며, (dog, cat, car, 등등)<br>  10개의 서로 다른 클래스가 있으므로 **K** = 10 이다.    

- **Linear Classifier**
    - 강의 노트에서는 가장 단순한 함수인 linear mapping 부터 시작한다.

$$
f(x_i, W, b) =  W x_i + b
$$

- 위 식에서는 이미지 **X<sub>i</sub>**가 열 벡터 형태 [D x 1]로 나타날 수 있다는 것을 가정하였다.
- 행렬 **W**([K x D])와 벡터 **b**는 위 함수의 parameter라고 할 수 있다. (우리가 정해야 하기 때문)
  - **W**는 가중치(**weights**), **b** 편향(**bias vector**)라고 부르기도 한다.
  - 이 둘은 입력 데이터(x<sub>i</sub>)와 상호작용없이 output score에 영향을 미친다.

- 밑에는 강의 노트에서 언급한 내용을 적어보았다.ㄴ

  >한 번의 행렬곱 **W**x<sub>i</sub> 만으로 10개의 다른 분류기(각 클래스마다 하나씩)를 병렬로 계산하는 효과를 나타내고 있다. 이 때 **W**의 각 행이 하나의 분류기 역할을 하고 있다고 보면된다.
  >
  >Parameter인 **W, b**를 우리가 조절할 수 있다. 실제로, 우리가 해야할 일은 score function의 output 실제 label과 최대한 일치하도록 이 parameter들을 조절하는 것이다.
  >
  >이러한 방식의 장점은 학습(training)이 끝난 이후에 **W, b**만 남기 때문에 학습시에 사용했던 데이터들이 필요 없어 빠르게 test를 진행 할 수 있다는 것이다.
  >
  >마지막으로, 행렬곱 연산 **W**x<sub>i</sub> 한번과 **b**(bias)를 한번 더해주면 끝나기 때문에<br>학습된 모든 데이터에 L1혹은 L2 distance를 비교하는 것과 비교하면 매우 빠르다는 것을 알 수 있다. 



### 2-1. Interpreting a linear classifier

---

- 이제 앞에서 나왔던 함수에 대해 자세히 알아보자
- 먼저 가중치 **W**에 들어가는 값들은 어떤 의미를 지닐까?
  - **W**의 각 요소들의 값은 **특정 위치에서 이미지의 픽셀(색상)값을 선호하거나 선호하지 않는다**는 것을 보여준다.
  - 예를들어 "배(ship)" 이미지 클래스의 경우는 보통 바다를 배경으로 하기 때문에 가장자리에 파란색이 많을 것이라고 예상해 볼 수 있다. 그렇다면 이미지의 Blue 채널에 곱해지는 가중치 **W**에 양의 값을 주고, Red와 Green 채널에 곱해지는 가중치 **W**에는 음의 값을 주어 분류기가 파란색을 선호한다는 것을 보여줄 수 있다. (R, G, B로 나눈 이유는 보통 이미지가 r,g,b 3차원 배열로 구성되기 때문이다.)

- 아래 그림은 이미지에서 클래스 스코어로 매핑하는 것을 보여준다.

  ![imagemap](/assets/images/cs231n/imagemap.jpg)

- 실제로는 R, G, B 각각에 대응하는 필터(**W**)가 3개 있어야 하지만 위에서는 한개로 축약해서 나타냈다.

- dog score가 437.9로 가장 높아 이 분류기는 input image(고양이)를 dog 클래스로 분류할 것이다.<br>잘못된 분류기의 예시를 보여준다고 할 수 있다. 따라서, **W**의 parameter 조절을 통해 cat score가 가장 높게 나타나도록 해야 할 것이다.

- **W**의 행들을 자세히 보자 첫 번째 행과 x<sub>i</sub>의 곱연산은 cat score에 매핑된다, 이처럼 **W**의 각 행들이 하나의 분류기에 해당한다는 것을 알 수 있다.



- 다음은 이미지와 고차원 공간 상의 점에 대한 비유이다.

  ![pixelspace](/assets/images/cs231n/pixelspace.jpeg)

- 위의 그림은 **3072-차원의 이미지 벡터들을 2-차원으로 축소**시킨 것을 나타낸 것이다.
- **W**의 각 행의 parameter값을 변경하는 것은 위의 직선들을 회전시키는 것이고,<br>**b**의 값을 변화시키는 것은 위의 직선들을 평행이동 시키는 것이라고 한다.



#### 2-1-1. Interpretation of linear classifiers as template matching

---

- 가중치 **W**에 대한 다른 해석이다.

- 앞에서는 **W**의 각 행들을 하나의 분류기로 봤다면 여기서는 **각 행들을 하나의 템플릿(template)으로 본다**(템플릿을 prototype으로 부르는 경우도 있다고 한다).

- 이렇게 볼 수 있는 근거는 이미지의 각 클래스 score는 **W**의 템플릿(열)과 이미지를 내적(dot product)하여 구해지고, 이 스코어를 기준으로 가장 잘 맞는(fits) 것을 찾기 때문이다.

- 결국 이 소리는 **linear classifier가 템플릿 매칭을 하고 있다**는 것과 동치라는데 솔직히 무슨 말인지 잘 모르겠다...

- 다르게는 NN과 유사하다고 한다.
  - NN에서 모든 학습 이미지를 사용하지 않고 각 클래스마다 한장의 이미지만 놔두는 것.

  - 또한 L1, L2 distance를 사용하는 것이 아니라 입력 이미지와 각 클래스 이미지를 내적(dot product)한 값을 사용한다.

    ![templates](/assets/images/cs231n/templates.jpg)

  - 각 클래스를 대표하는 템플릿(NN의 training 과정이 끝났을때 저장된 이미지)는 위의 그림처럼 나타날 수 있다고 한다.

  - 결국, linear classifier는 새로운 이미지 X가 들어오면 위의 10개의 클래스 이미지(템플릿)들과 내적한 값을 비교하여 어떤 클래스인지 분류한다는 말이다.

  - 강의 노트에서는 추가적으로 저 템플릿들에 대해 설명한다.

    > 말(horse) 템플릿의 경우 머리가 두 개 인것처럼 보이는데, 이는 CIFAR-10 데이터 셋에 속한 말 클래스의 이미지들이 왼쪽을 바라보고 있는 말, 오른쪽을 바라보고 있는 말<br>두 종류가 있다는 것을 알려준다.
    >
    > 또한 자동차(car) 템플릿의 경우 색갈이 붉은색 계열로 나타는 것을 확인할 수 있는데, 이것은 CIFAR-10 데이터 셋에 속한 자동차 클래스의 이미지들이 대부분 붉은색 자동차 라는 것을 알려준다.
    >
    > 만약, 파란색 자동차 이미지가 입력으로 들어온다면 linear classifier는 배(ship) 템플릿이 전반적으로 푸른색을 띄기 때문에 배(ship) 클래스로 잘못 판단할 수도 있다.



#### 2-1-2. Bias trick

---

- 여기서는 **W, b** 두 개의 parameter를 하나로 나타내는 트릭을 소개한다.

- 하나로 나타내는 이유는 앞으로 계속 식을 쓸 때 두개의 parameter를 계속 표시하는 것은 번거로울 수 있기 때문이다.

- 말보다는 그림으로 보는 편이 이해하기 쉬워서 강의 노트의 그림을 첨부한다.

  ![wb](/assets/images/cs231n/wb.jpeg)



### 2-2. Image data preprocessing

---

- 나중에 다시 다루는 내용이니 건너뛰어도 상관 없을거 같다.
- 머신 러닝에서 입력 특징(features)들을 **normalization**하는 것이 일반적이라고 한다.
- 이미지를 다룰때는 보통 이미지의 각 픽셀 값이 [0 ~ 255] 사이의 값이기 때문에,<br>이 값들을 평균내면 양의 값을 가지게 된다.<br>그러나 이미지 픽셀 값들의 평균이 0이 되도록 하는것이 좋다고 한다.<br>이는 전체 이미지의 픽셀 값들을 모두 더해서 평균낸다음 각 픽셀에서 평균값을 빼주면 된다고 한다.
- 이렇게 하면 이미지의 각 픽셀이 [-127 ~ 127] 사이의 값을 가지게 되는데,<br>더 나아가서 이것들의 크기를 조절하여(scaling) [-1~1] 사이의 값으로 변환 한다고도 한다.



## 3. Loss Function

- 앞에서는 각 이미지의 픽셀 값을 클래스 스코어로 매핑하는 linear classifier에 대해 배웠다.

- 지금 부터는 **우리가 훈련시킨 classifier가 어느정도의 성능을 내는지** 보여주는 **손실 함수(loss function)**에 대해서 배운다.

- 손실 함수의 값이 크면 성능이 나쁘다는 것이고, 작으면 성능이 좋다는 것이다.

- 앞으로 이 손실 함수를 이용해 parameter(가중치와 bias)값을 조정(tuning)하여 우리의 classifier가 더 좋은 성능을 내도록 할 것이다.

- 강의 노트에서는 아래와 같이 손실 함수를 설명한다.

  > We are going to measure our unhappiness with outcomes such as this one with a **loss function**  

- loss function을 cost function 혹은 objective라고 부르는 경우도 있다고 한다.



### 3-1. Multiclass Support Vector Machine loss(SVM loss)

---

- 이제 손실 함수의 첫 번째 예시인 SVM loss에 대해 알아보자.
- SVM loss의 식을 살펴보면 아래와 같다.

$$
L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)
$$

- **SVM loss의 목표는 가중치(weights)값을 조절하여 정답 클래스의 값이 오답 클래스의 값보다 최소한 Δ 만큼 크게 나오도록 하는 것**이다.

- 위의 식에서 **s<sub>j</sub>는 j번째 클래스에 대한 점수**를 나타낸다. (정답 클래스는 제외)

- **s<sub>yi</sub>의 경우는 입력 x<sub>i</sub>가 들어왔을 때 정답 클래스에 대한 점수**를 나타낸다.

- 쉬운 설명을 위해 CS231n Lecture 3 강의 슬라이드를 첨부한다.

  ![svmloss1](/assets/images/cs231n/svmloss1.PNG)

- 간단하게 Δ = 0.1 이라고 해보자,

  - L<sub>1</sub>의 경우는 정답 클래스가 고양이가 된다. (단순히 cat, car, frog 순서로 나열되어 있어서 제가 임의로 첫번째라고 정함)
  - 그렇다면 S<sub>yi</sub>의 값은 고양의 클래스의 값이기 때문에 3.2가 되고
  - S<sub>j</sub>의 경우는 정답 클래스를 제외한 나머지 점수가 되므로 각각 5.1 과 -1.7 라는 것을 알 수 있다.
  - 계산을 해보면 L<sub>1</sub> = max(0, 5.1 - 3.2 + 0.1) + max(0, -1.7 - 3.2 + 0.1) = 2.0 임을 알 수 있다.
    - 여기서 첫번째 max에서 정답 클래스의 값(3.2)이 오답 클래스의 값(5.1) 보다 1.9 만큼 작기 때문에 1.9에 Δ값 0.1 이 더해져 오차가 2.0이 나오는 것이다.
    - 두번째 max의 경우는 정답 클래스의 값(3.2)가 오답 클래스의 값(-1.7) 보다 크고 이 차이가 Δ 보다 크기 때문에 오차가 0.0이 나온다.
  - 이렇게 고양이 말고도 남은 두 개의 클래스에 대해서도 구한다음 L<sub>1</sub>+L<sub>2</sub>+L<sub>3</sub>의 값을 구하면 SVM loss가 된다.

- 여기서 max(0, -) 꼴로 나타나는 function을 **hinge loss**라고 부른다.

  - max(0, -)<sup>2</sup>의 꼴로 나타내면 L2-SVM 이라고 부른다고 한다.
  - hinge loss와 L2-SVM 중에 좋은 성능을 내는 것을 사용하면 된다고 한다.

- 강의 노트에 SVM loss에 대한 추가적인 설명이 있어서 첨부한다.

  ![margin](/assets/images/cs231n/margin.jpg)

  - 우리는 손실 함수의 결과(output)를 통해 가중치(weights)의 값을 조절하여 정답 클래스와 나머지 클래스에 대한 점수 차이가 최소한 Δ 만큼은 나도록 해야한다. 만약 Δ 이하로 차이가 난다면 그만큼 손실 함수의 값이 커질 것이다.



### 3.2 Regularization

---

- SVM loss를 보면 완벽해 보이지만 하나 문제점이 있다.
- 바로 최적의 가중치 **W**의 값을 unique하게 결정하기 어렵다는 것이다.
  - 여기서는 손실 함수의 값을 0으로 만드는 것을 최적의 **W** 값이라 하겠다.
- 

