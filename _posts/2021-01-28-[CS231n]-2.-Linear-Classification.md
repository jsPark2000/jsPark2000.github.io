---
layout: post
title:  "[CS231n] 2. Linear Classification"
author: jspark
date: '2021-01-28 16:15:00 +0900'
category: CS231n
use_math: true
---


## 1. Linear Classification(선형 분류)

- CS231n의 [유튜브 강의 내용](https://youtu.be/OoUX-nOEjG0)과 [강의 노트](https://cs231n.github.io/linear-classify/)를 참고하여 작성하였습니다.
- 이 포스트는 CS231n - Lecture2~3 의 내용을 포함합니다.
- 데스크탑이나 노트북의 경우 글꼴 크기를 확대(ctrl + 마우스 스크롤) 하여 보는 것을 추천합니다.
- 파이썬 코드는 글의 내용에 포함되지 않습니다.



### 1-1. Overview

---

- 지난 시간에 배웠던 Image Classificaion을 확장시켜 Neural Network와 Convolution Neural Network를 배우는 Section이다.
- 자세히는<br>**score function**: raw data를 class score로 매핑해주는 function.<br>**loss function**: 모델의 predicted score와 실제 label의 차이를 보여주는 function.<br>**Optimization Problem**: score function의 parameter에 대한 loss function을 최소화 하는것<br>에 대한 내용을 다룬다.



## 2. Parameterized mapping from images to label scores

- **Score function**
  - 이미지들의 픽셀값을 각 클래스들의 점수로 매핑해주는 함수.
  - 이미지 X 가 있고 클래스가 {고양이, 강아지, 배} 3개가 있다고 한다면 score function은<br> 이미지 X를 (4, 6, 2) 와 같이 각 클래스들에 대한 점수로 매핑해준다.
- 앞으로는 강의 교안에서 나오는 예시로 설명하도록 하겠다.

학습 데이터셋 이미지들인

$$
x_i \in R^D
$$

가 있고, 각각이 해당 라벨

$$
y_i
$$

를 갖고 있다고 하자. 여기서

$$
i = 1 \dots N,   y_i \in \{ 1 \dots K \}
$$

이다.

  학습할 데이터 **N** 개가 있고 (각각은 **D** 차원의 벡터이다.), 총 **K** 개의 서로 다른 카테고리(클래스)가 있다.<br>  예를 들어, CIFAR-10 에서는 **N** = 50,000 개의 학습 데이터 이미지들이 있고,<br>  각각은 **D** = 32 x 32 x 3 = 3072 픽셀로 이루어져 있으며, (dog, cat, car, 등등)<br>  10개의 서로 다른 클래스가 있으므로 **K** = 10 이다.    

- **Linear Classifier**
    - 강의 노트에서는 가장 단순한 함수인 linear mapping 부터 시작한다.

$$
f(x_i, W, b) =  W x_i + b
$$

- 위 식에서는 이미지 **X<sub>i</sub>**가 열 벡터 형태 [D x 1]로 나타날 수 있다는 것을 가정하였다.
- 행렬 **W**([K x D])와 벡터 **b**는 위 함수의 parameter라고 할 수 있다. (우리가 정해야 하기 때문)
  - **W**는 가중치(**weights**), **b** 편향(**bias vector**)라고 부르기도 한다.
  - 이 둘은 입력 데이터(x<sub>i</sub>)와 상호작용없이 output score에 영향을 미친다.

- 밑에는 강의 노트에서 언급한 내용을 적어보았다.ㄴ

  >한 번의 행렬곱 **W**x<sub>i</sub> 만으로 10개의 다른 분류기(각 클래스마다 하나씩)를 병렬로 계산하는 효과를 나타내고 있다. 이 때 **W**의 각 행이 하나의 분류기 역할을 하고 있다고 보면된다.
  >
  >Parameter인 **W, b**를 우리가 조절할 수 있다. 실제로, 우리가 해야할 일은 score function의 output 실제 label과 최대한 일치하도록 이 parameter들을 조절하는 것이다.
  >
  >이러한 방식의 장점은 학습(training)이 끝난 이후에 **W, b**만 남기 때문에 학습시에 사용했던 데이터들이 필요 없어 빠르게 test를 진행 할 수 있다는 것이다.
  >
  >마지막으로, 행렬곱 연산 **W**x<sub>i</sub> 한번과 **b**(bias)를 한번 더해주면 끝나기 때문에<br>학습된 모든 데이터에 L1혹은 L2 distance를 비교하는 것과 비교하면 매우 빠르다는 것을 알 수 있다. 



### 2-1. Interpreting a linear classifier

---

- 이제 앞에서 나왔던 함수에 대해 자세히 알아보자
- 먼저 가중치 **W**에 들어가는 값들은 어떤 의미를 지닐까?
  - **W**의 각 요소들의 값은 **특정 위치에서 이미지의 픽셀(색상)값을 선호하거나 선호하지 않는다**는 것을 보여준다.
  - 예를들어 "배(ship)" 이미지 클래스의 경우는 보통 바다를 배경으로 하기 때문에 가장자리에 파란색이 많을 것이라고 예상해 볼 수 있다. 그렇다면 이미지의 Blue 채널에 곱해지는 가중치 **W**에 양의 값을 주고, Red와 Green 채널에 곱해지는 가중치 **W**에는 음의 값을 주어 분류기가 파란색을 선호한다는 것을 보여줄 수 있다. (R, G, B로 나눈 이유는 보통 이미지가 r,g,b 3차원 배열로 구성되기 때문이다.)

- 아래 그림은 이미지에서 클래스 스코어로 매핑하는 것을 보여준다.

  ![imagemap](/assets/images/cs231n/imagemap.jpg)

- 실제로는 R, G, B 각각에 대응하는 필터(**W**)가 3개 있어야 하지만 위에서는 한개로 축약해서 나타냈다.

- dog score가 437.9로 가장 높아 이 분류기는 input image(고양이)를 dog 클래스로 분류할 것이다.<br>잘못된 분류기의 예시를 보여준다고 할 수 있다. 따라서, **W**의 parameter 조절을 통해 cat score가 가장 높게 나타나도록 해야 할 것이다.

- **W**의 행들을 자세히 보자 첫 번째 행과 x<sub>i</sub>의 곱연산은 cat score에 매핑된다, 이처럼 **W**의 각 행들이 하나의 분류기에 해당한다는 것을 알 수 있다.



- 다음은 이미지와 고차원 공간 상의 점에 대한 비유이다.

  ![pixelspace](/assets/images/cs231n/pixelspace.jpeg)

- 위의 그림은 **3072-차원의 이미지 벡터들을 2-차원으로 축소**시킨 것을 나타낸 것이다.
- **W**의 각 행의 parameter값을 변경하는 것은 위의 직선들을 회전시키는 것이고,<br>**b**의 값을 변화시키는 것은 위의 직선들을 평행이동 시키는 것이라고 한다.



#### 2-1-1. Interpretation of linear classifiers as template matching

---

- 가중치 **W**에 대한 다른 해석이다.
- 앞에서는 **W**의 각 행들을 하나의 분류기로 봤다면 여기서는 **각 행들을 하나의 템플릿(template)으로 본다**(템플릿을 prototype으로 부르는 경우도 있다고 한다).
- 이렇게 볼 수 있는 근거는 이미지의 각 클래스 score는 **W**의 템플릿()

