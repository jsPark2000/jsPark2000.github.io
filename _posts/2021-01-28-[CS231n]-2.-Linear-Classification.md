---
layout: post
title:  "[CS231n] 2. Linear Classification"
author: jspark
date: '2021-01-28 16:15:00 +0900'
category: CS231n
use_math: true
---


## 1. Linear Classification(선형 분류)

- CS231n의 [유튜브 강의 내용](https://youtu.be/OoUX-nOEjG0)과 [강의 노트](https://cs231n.github.io/linear-classify/)를 참고하여 작성하였습니다.
- 이 포스트는 CS231n - Lecture2~3 의 내용을 포함합니다.
- 데스크탑이나 노트북의 경우 글꼴 크기를 확대(ctrl + 마우스 스크롤) 하여 보는 것을 추천합니다.
- 파이썬 코드는 글의 내용에 포함되지 않습니다.



### 1-1. Overview

---

- 지난 시간에 배웠던 Image Classificaion을 확장시켜 Neural Network와 Convolution Neural Network를 배우는 Section이다.
- 자세히는<br>**score function**: raw data를 class score로 매핑해주는 function.<br>**loss function**: 모델의 predicted score와 실제 label의 차이를 보여주는 function.<br>**Optimization Problem**: score function의 parameter에 대한 loss function을 최소화 하는것<br>에 대한 내용을 다룬다.



## 2. Parameterized mapping from images to label scores

- **Score function**
  - 이미지들의 픽셀값을 각 클래스들의 점수로 매핑해주는 함수.
  - 이미지 X 가 있고 클래스가 {고양이, 강아지, 배} 3개가 있다고 한다면 score function은<br> 이미지 X를 (4, 6, 2) 와 같이 각 클래스들에 대한 점수로 매핑해준다.
- 앞으로는 강의 교안에서 나오는 예시로 설명하도록 하겠다.

학습 데이터셋 이미지들인

$$
x_i \in R^D
$$

가 있고, 각각이 해당 라벨

$$
y_i
$$

를 갖고 있다고 하자. 여기서

$$
i = 1 \dots N,   y_i \in \{ 1 \dots K \}
$$

이다.

  학습할 데이터 **N** 개가 있고 (각각은 **D** 차원의 벡터이다.), 총 **K** 개의 서로 다른 카테고리(클래스)가 있다.<br>  예를 들어, CIFAR-10 에서는 **N** = 50,000 개의 학습 데이터 이미지들이 있고,<br>  각각은 **D** = 32 x 32 x 3 = 3072 픽셀로 이루어져 있으며, (dog, cat, car, 등등)<br>  10개의 서로 다른 클래스가 있으므로 **K** = 10 이다.    

- **Linear Classifier**
    - 강의 노트에서는 가장 단순한 함수인 linear mapping 부터 시작한다.

$$
f(x_i, W, b) =  W x_i + b
$$

- 위 식에서는 이미지 **X<sub>i</sub>**가 열 벡터 형태 [D x 1]로 나타날 수 있다는 것을 가정하였다.
- 행렬 **W**([K x D])와 벡터 **b**는 위 함수의 parameter라고 할 수 있다. (우리가 정해야 하기 때문)
  - **W**는 가중치(**weights**), **b** 편향(**bias vector**)라고 부르기도 한다.
  - 이 둘은 입력 데이터(x<sub>i</sub>)와 상호작용없이 output score에 영향을 미친다.

- 밑에는 강의 노트에서 언급한 내용을 적어보았다.ㄴ

  >한 번의 행렬곱 **W**x<sub>i</sub> 만으로 10개의 다른 분류기(각 클래스마다 하나씩)를 병렬로 계산하는 효과를 나타내고 있다. 이 때 **W**의 각 행이 하나의 분류기 역할을 하고 있다고 보면된다.
  >
  >Parameter인 **W, b**를 우리가 조절할 수 있다. 실제로, 우리가 해야할 일은 score function의 output 실제 label과 최대한 일치하도록 이 parameter들을 조절하는 것이다.
  >
  >이러한 방식의 장점은 학습(training)이 끝난 이후에 **W, b**만 남기 때문에 학습시에 사용했던 데이터들이 필요 없어 빠르게 test를 진행 할 수 있다는 것이다.
  >
  >마지막으로, 행렬곱 연산 **W**x<sub>i</sub> 한번과 **b**(bias)를 한번 더해주면 끝나기 때문에<br>학습된 모든 데이터에 L1혹은 L2 distance를 비교하는 것과 비교하면 매우 빠르다는 것을 알 수 있다. 



### 2-1. Interpreting a linear classifier

---

- 이제 앞에서 나왔던 함수에 대해 자세히 알아보자
- 먼저 가중치 **W**에 들어가는 값들은 어떤 의미를 지닐까?
  - **W**의 각 요소들의 값은 **특정 위치에서 이미지의 픽셀(색상)값을 선호하거나 선호하지 않는다**는 것을 보여준다.
  - 예를들어 "배(ship)" 이미지 클래스의 경우는 보통 바다를 배경으로 하기 때문에 가장자리에 파란색이 많을 것이라고 예상해 볼 수 있다. 그렇다면 이미지의 Blue 채널에 곱해지는 가중치 **W**에 양의 값을 주고, Red와 Green 채널에 곱해지는 가중치 **W**에는 음의 값을 주어 분류기가 파란색을 선호한다는 것을 보여줄 수 있다. (R, G, B로 나눈 이유는 보통 이미지가 r,g,b 3차원 배열로 구성되기 때문이다.)

- 아래 그림은 이미지에서 클래스 스코어로 매핑하는 것을 보여준다.

  ![imagemap](/assets/images/cs231n/imagemap.jpg)

- 실제로는 R, G, B 각각에 대응하는 필터(**W**)가 3개 있어야 하지만 위에서는 한개로 축약해서 나타냈다.
- dog score가 437.9로 가장 높아 이 분류기는 input image(고양이)를 dog 클래스로 분류할 것이다.<br>잘못된 분류기의 예시를 보여준다고 할 수 있다. 따라서, **W**의 parameter 조절을 통해 cat score가 가장 높게 나타나도록 해야 할 것이다.
- **W**의 행들을 자세히 보자 첫 번째 행과 x<sub>i</sub>의 곱연산은 cat score에 매핑된다, 이처럼 **W**의 각 행들이 하나의 분류기에 해당한다는 것을 알 수 있다.

- 다음은 이미지와 고차원 공간 상의 점에 대한 비유이다.

  ![pixelspace](/assets/images/cs231n/pixelspace.jpeg)

- 위의 그림은 **3072-차원의 이미지 벡터들을 2-차원으로 축소**시킨 것을 나타낸 것이다.
- **W**의 각 행의 parameter값을 변경하는 것은 위의 직선들을 회전시키는 것이고,<br>**b**의 값을 변화시키는 것은 위의 직선들을 평행이동 시키는 것이라고 한다.



#### 2-1-1. Interpretation of linear classifiers as template matching

---

- 가중치 **W**에 대한 다른 해석이다.
- 앞에서는 **W**의 각 행들을 하나의 분류기로 봤다면 여기서는 **각 행들을 하나의 템플릿(template)으로 본다**(템플릿을 prototype으로 부르는 경우도 있다고 한다).
- 이렇게 볼 수 있는 근거는 이미지의 각 클래스 score는 **W**의 템플릿(행)과 이미지를 내적(dot product)하여 구해지고, 이 스코어를 기준으로 가장 잘 맞는(fits) 것을 찾기 때문이다.
- 결국 이 소리는 **linear classifier가 템플릿 매칭을 하고 있다**는 것과 동치라는데 솔직히 무슨 말인지 잘 모르겠다...
- 다르게는 NN과 유사하다고 한다.
  - NN에서 모든 학습 이미지를 사용하지 않고 각 클래스마다 한장의 이미지만 놔두는 것.
  - 또한 L1, L2 distance를 사용하는 것이 아니라 입력 이미지와 각 클래스 이미지를 내적(dot product)한 값을 사용한다.

    ![templates](/assets/images/cs231n/templates.jpg)

  - 각 클래스를 대표하는 템플릿(NN의 training 과정이 끝났을때 저장된 이미지)는 위의 그림처럼 나타날 수 있다고 한다.
  - 결국, linear classifier는 새로운 이미지 X가 들어오면 위의 10개의 클래스 이미지(템플릿)들과 내적한 값을 비교하여 어떤 클래스인지 분류한다는 말이다.

  - 강의 노트에서는 추가적으로 저 템플릿들에 대해 설명한다.

    > 말(horse) 템플릿의 경우 머리가 두 개 인것처럼 보이는데, 이는 CIFAR-10 데이터 셋에 속한 말 클래스의 이미지들이 왼쪽을 바라보고 있는 말, 오른쪽을 바라보고 있는 말<br>두 종류가 있다는 것을 알려준다.
    >
    > 또한 자동차(car) 템플릿의 경우 색갈이 붉은색 계열로 나타는 것을 확인할 수 있는데, 이것은 CIFAR-10 데이터 셋에 속한 자동차 클래스의 이미지들이 대부분 붉은색 자동차 라는 것을 알려준다.
    >
    > 만약, 파란색 자동차 이미지가 입력으로 들어온다면 linear classifier는 배(ship) 템플릿이 전반적으로 푸른색을 띄기 때문에 배(ship) 클래스로 잘못 판단할 수도 있다.



#### 2-1-2. Bias trick

---

- 여기서는 **W, b** 두 개의 parameter를 하나로 나타내는 트릭을 소개한다.
- 하나로 나타내는 이유는 앞으로 계속 식을 쓸 때 두개의 parameter를 계속 표시하는 것은 번거로울 수 있기 때문이다.

- 말보다는 그림으로 보는 편이 이해하기 쉬워서 강의 노트의 그림을 첨부한다.

  ![wb](/assets/images/cs231n/wb.jpeg)



### 2-2. Image data preprocessing

---

- 나중에 다시 다루는 내용이니 건너뛰어도 상관 없을거 같다.
- 머신 러닝에서 입력 특징(features)들을 **normalization**하는 것이 일반적이라고 한다.
- 이미지를 다룰때는 보통 이미지의 각 픽셀 값이 [0 ~ 255] 사이의 값이기 때문에,<br>이 값들을 평균내면 양의 값을 가지게 된다.<br>그러나 이미지 픽셀 값들의 평균이 0이 되도록 하는것이 좋다고 한다.<br>이는 전체 이미지의 픽셀 값들을 모두 더해서 평균낸다음 각 픽셀에서 평균값을 빼주면 된다고 한다.
- 이렇게 하면 이미지의 각 픽셀이 [-127 ~ 127] 사이의 값을 가지게 되는데,<br>더 나아가서 이것들의 크기를 조절하여(scaling) [-1~1] 사이의 값으로 변환 한다고도 한다.



## 3. Loss Function

- 앞에서는 각 이미지의 픽셀 값을 클래스 스코어로 매핑하는 linear classifier에 대해 배웠다.
- 지금 부터는 **우리가 훈련시킨 classifier가 어느정도의 성능을 내는지** 보여주는 **손실 함수(loss function)**에 대해서 배운다.
- 손실 함수의 값이 크면 성능이 나쁘다는 것이고, 작으면 성능이 좋다는 것이다.
- 앞으로 이 손실 함수를 이용해 parameter(가중치와 bias)값을 조정(tuning)하여 우리의 classifier가 더 좋은 성능을 내도록 할 것이다.

- 강의 노트에서는 아래와 같이 손실 함수를 설명한다.

  > We are going to measure our unhappiness with outcomes such as this one with a **loss function**  

- loss function을 cost function 혹은 objective라고 부르는 경우도 있다고 한다.



### 3-1. Multiclass Support Vector Machine loss(SVM loss)

---

- 이제 손실 함수의 첫 번째 예시인 SVM loss에 대해 알아보자.
- SVM loss의 식을 살펴보면 아래와 같다.

$$
L_i = \sum_{j\neq y_i} \max(0, s_j - s_{y_i} + \Delta)
$$

- **SVM loss의 목표는 가중치(weights)값을 조절하여 정답 클래스의 값이 오답 클래스의 값보다 최소한 Δ 만큼 크게 나오도록 하는 것**이다.
- 위의 식에서 **s<sub>j</sub>는 j번째 클래스에 대한 점수**를 나타낸다. (정답 클래스는 제외)

$$
s_j = f(x_i, W)_j
$$

- **s<sub>yi</sub>의 경우는 입력 x<sub>i</sub>가 들어왔을 때 정답 클래스에 대한 점수**를 나타낸다.

- 쉬운 설명을 위해 CS231n Lecture 3 강의 슬라이드를 첨부한다.

  ![svmloss1](/assets/images/cs231n/svmloss1.PNG)

- 간단하게 Δ = 0.1 이라고 해보자,
  - L<sub>1</sub>의 경우는 정답 클래스가 고양이가 된다. (단순히 cat, car, frog 순서로 나열되어 있어서 제가 임의로 첫번째라고 정함)
  - 그렇다면 S<sub>yi</sub>의 값은 고양의 클래스의 값이기 때문에 3.2가 되고
  - S<sub>j</sub>의 경우는 정답 클래스를 제외한 나머지 점수가 되므로 각각 5.1 과 -1.7 라는 것을 알 수 있다.
  - 계산을 해보면 L<sub>1</sub> = max(0, 5.1 - 3.2 + 0.1) + max(0, -1.7 - 3.2 + 0.1) = 2.0 임을 알 수 있다.
    - 여기서 첫번째 max에서 정답 클래스의 값(3.2)이 오답 클래스의 값(5.1) 보다 1.9 만큼 작기 때문에 1.9에 Δ값 0.1 이 더해져 오차가 2.0이 나오는 것이다.
    - 두번째 max의 경우는 정답 클래스의 값(3.2)가 오답 클래스의 값(-1.7) 보다 크고 이 차이가 Δ 보다 크기 때문에 오차가 0.0이 나온다.
  - 이렇게 고양이 말고도 남은 두 개의 클래스에 대해서도 구한다음 L<sub>1</sub>+L<sub>2</sub>+L<sub>3</sub>의 값을 구하면 SVM loss가 된다.

- 여기서 max(0, -) 꼴로 나타나는 function을 **hinge loss**라고 부른다.
  - max(0, -)<sup>2</sup>의 꼴로 나타내면 L2-SVM 이라고 부른다고 한다.
  - hinge loss와 L2-SVM 중에 좋은 성능을 내는 것을 사용하면 된다고 한다.

- 강의 노트에 SVM loss에 대한 추가적인 설명이 있어서 첨부한다.

  ![margin](/assets/images/cs231n/margin.jpg)

  - 우리는 손실 함수의 결과(output)를 통해 가중치(weights)의 값을 조절하여 정답 클래스와 나머지 클래스에 대한 점수 차이가 최소한 Δ 만큼은 나도록 해야한다. 만약 Δ 이하로 차이가 난다면 그만큼 손실 함수의 값이 커질 것이다.



### 3-2 Regularization

---

- SVM loss를 보면 완벽해 보이지만 하나 문제점이 있다.
- 바로 최적의 가중치 **W**의 값을 unique하게 결정하기 어렵다는 것이다.
  - 여기서는 손실 함수의 값을 0으로 만드는 것을 최적의 **W** 값이라 하겠다.
- 만약 최적의 가중치 **W**가 손실 함수의 값을 0으로 만든다면 λ**W**(λ>1) 또한 손실 함수의 값을 0으로 만들기 때문에 거의 무한대 경우의 **W**가 생기게 된다.
  - 단순히 가중치 값에 λ(λ>1)를 곱하는 것은 작은 클래스의 값은 더 작게, 정답 클래스의 값은 더 크게 만든다. (streches absolute difference)
- 따라서 이러한 ambiguity를 해소하기 위해 **regularization** 개념이 등장하게 되었다.
- 규제 함수는 기호로 **R(W)**로 나타낸다.


- **L2 norm**을 사용한 규제 함수의 식을 한번 살펴보자

$$
R(W) = \sum_k\sum_l W_{k,l}^2
$$

- 간단하게 말하면 가중치 **W**의 각 요소를 제곱하여 더한것이다.
  - 즉, Input data에 대한 function이 아니다.
- **W**의 각 요소의 값이 커지면 규제 함수의 값이 커지고 결국 손실 함수의 값이 커지게 된다.
  - **W**의 각 요소의 값을 작게 만들도록 하는 효과를 낸다.
- 이제 앞에서 배웠던 SVM 요소와 합쳐 **full Multiclass SVM loss**를 정의할 수 있게 되었다.

$$
L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss} \\\\
$$

- 여기서 알아두어야 하는 특징이 몇개 있다. (L2 norm 기준)
  - 규제 함수 앞에 hyperparameter λ 가 붙어 있어 우리가 규제의 정도를 조절할 수 있다는 것
    - cross-validation을 통해 최적의 λ값을 정해야한다.
  - 규제함수 **R(W)**가 0이 되는 경우는 가중치 **W**의 각 요소가 0인 경우 밖에는 없으므로<br>사실상 손실 함수(loss function)의 값이 0이 되는것은 어렵다는 것
  - 큰 가중치 값에 패널티를 줘서 특정한 입력값의 차원(dimension)이 score에 큰 영향 주는 것을 방지하는 것
    - **w<sub>1</sub>=[1, 0, 0, 0]** 이고 **w<sub>2</sub> = [0.25, 0.25, 0.25, 0.25]** , **x = [1, 1, 1, 1]** 이라고 하자
    - **w<sup>t</sup><sub>1</sub>x = w<sup>t</sup><sub>2</sub>x = 1** (내적 값)이 되는데 반해
    - w<sub>1</sub>에 대한 L2 규제는 1 이고, w<sub>2</sub>에 대한 L2 규제(위에서 R(W))는 4 * (0.25)<sup>2</sup>= 0.25 가 된다.
    - 따라서, L2 규제를 사용한 경우 w<sub>2</sub>를 선택하는 것이 손실 함수의 값이 줄어든다. 
    - L2 규제는 큰 가중치의 값에는 규제를 강하게, 작은 가중치의 값에는 규제를 약하게 주어, <br>가중치의 값을 최대한 고르게 분산되게 하여,<br>최종 score에 각 입력 차원의 값이 고르게 반영될 수 있도록 한다는 것
  
- bias **b**의 경우는 입력값의 차원이 score에 영향을 주는 것에 대해 가중치 **W**처럼 효과를 주지 못하기 때문에 규제 함수는 보통 가중치 **W**대한 식으로만 나타난다고 한다.

- 위의 **full Multiclass SVM loss**를 확장 시키면 아래와 같이 표현할수도 있다.

$$
L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2
$$

- 간단하게 **S<sub>j</sub>**를 linear score function **f(x<sub>i</sub> ; W)<sub>j</sub>**로 바꾼것이다.
  - 가중치 **W**의 j번째 열과 입력 x<sub>i</sub>를 행렬 곱 연산 한것



#### 3-2-1. Practical Considerations

---

- 앞에서 λ, Δ 가 나왔었다.

- 이는 hyperparameter로 우리가 설정해 줘야 하는 값인데

- 실질적으로 λ를 통한 조정만이 의미가 있다고 한다.
  
  - 아무리 Δ값을 조절해 봤자 가중치 **W**값을 늘리거나 줄이면서 대응하면 되기 때문이다.
  
- 따라서 보통 Δ = 1.0 으로 두고 λ 만 tuning 한다고 한다.

- **Binary Support Vector Machine**
  - 클래스가 2개인 경우에 사용한다고 한다.

$$
L_i = C \max(0, 1 - y_i w^Tx_i) + R(W)
$$

- C는 hyperparameter이고 y<sub>i</sub>는 -1, 1 둘중 하나의 값을 가진다.
- C는 λ와 반비례 관계에 있다
  - C가 커질수록 규제의 강도가 약해지고, 작아질수록 규제의 강도가 세짐



### 3-3. Softmax Classifier
---

- 앞에서 배운 SVM 말고 다른 손실 함수를 사용하는 예시이다.
- SVM의 경우는 **f(x<sub>i</sub>, W)**의 output을 각 클래스에 대한 점수(score)로 취급했다면,<br>Softmax classifier는 더 직관적인 결과를 내놓는다.
- Softmax classifier의 경우 hinge loss(max(0, -))를 cross-entropy loss 로 바꾸는데 그 형태는 아래와 같다.

$$
L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}
$$

- 여기서

$$
f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}
$$

- 이것을 softmax function 이라고 부른다.
- 이 cross-entropy와 관련한 설명은 [이곳](https://3months.tistory.com/436)에 잘 나와있다.
- 결과적으로 보자면 예측 값의 분포와 실제 label 값의 분포를 비슷하게 맞추는 것이 모델의 성능을 높인다는 말이다.



- **확률론적인 관점**에서 보면

$$
P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }
$$

- softmax classifier가 위와 같이 각 클래스에 대한 **정규화(normalization)된 확률 값**을 제공한다는 것을 알 수 있다.
  - 정규화 됬다는 의미는 각 확률 값을 더하면 1이 된다는 의미로 해석하면 된다.
-  따라서, **정답 클래스의 negative log likelihood(음의 로그우도) 값을 최소화 한다**는 의미로 해석할 수 있다.



### 3-4 SVM vs Softmax

---

- 먼저 강의 노트에 나와있는 그림을 보자

  ![3.8.svmvssoftmax](/assets/images/cs231n/3.8.svmvssoftmax.png)

- 가장 큰 특징은 SVM의 경우 3개의 클래스에 대해 (-2.85, 0.86, 0.28) 이런식의 점수를 내놓지만,<br>Softmax의 경우는 중간 과정에서 (0.016, 0.631, 0.353) 확률 값으로 내놓기 때문에 직관적으로 이해하기 쉽다는 것이다.

- 여기서 "확률"이라는 단어를 사용한것은 이러한 확률을 얼마나 높이고, 분산시킬지는 규제의 강도에 따라 달라지기 때문이다.
  
  - 극단적으로 규제의 강도를 높이면 (0.016, 0.631, 0.353) 이 (0.33, 0.33, 0.33)이 될 수 있기 때문
  - 이때문에 **softmax로 계산되는 확률은 신뢰도로 해석하는 것이 좋다**.
  
- 또한 SVM에서는 1.58, Softmax 에서는 1.04 라는 loss값을 내놓는데 이 둘을 비교하는 것은 무의미하다.
  
  - 서로 다른 손실 함수(loss function)를 사용했기 때문.
  
- Softmax의 과정을 단순하게 나타내면 아래와 같다.

  - unnormalized log probabilities가 [-1, 2, 0]이 되는 경우 Softmax function의 계산 과정

$$
[1, -2, 0] \rightarrow [e^1, e^{-2}, e^0] = [2.71, 0.14, 1] \rightarrow [0.7, 0.04, 0.26]
$$



#### 3-4-1 In practice, SVM and Softmax are usually comparable

---

- Softmax가 잘 작동하는 경우도, SVM이 더 잘 작동하는 경우도 있다고 한다.
- SVM의 경우는 정확히 분류했다고 생각하면 더 이상 학습을 진행하지 않는다.<br>정답 클래스의 점수가 다른 클래스 들의 점수보다 Δ 이상으로 커진다면 loss가 0이 되기 때문이다.
  - 이는 트럭과 개구리 처럼 완전히 다른 클래스를 구분할 때 유리하다. (속도가 빠르기 때문)
  - 하지만 트럭들의 종류 volvo, benz 처럼 유사한 클래스를 구분하는데는 나쁜 성능을 보일 것이다.
- Softmax의 경우는 끝까지 분류하려고 노력한다.<br>확률이 1이 되는 경우는 거의 없기 때문에 항상 loss 개선의 여지가 있기 때문이다.





## 4. 글을 마치며

- 이번 글에서는 Linear classification에 대해 알아보면서<br>가장 먼저 간단한 선형 분류기 f(x<sub>i</sub>, W, b) = Wx<sub>i</sub> + b 에 대해 알아보고,<br>그 이후에 손실 함수(loss function) SVM과 Softmax에 대하여 알아 보았다.
- 다음 글은 Optimization(최적화)에 대하여 쓸 예정이다.