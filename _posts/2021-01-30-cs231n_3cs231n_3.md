---
layout: post
title:  "[CS231n] 3. Optimization"
author: jspark
date: '2021-01-30 10:15:00 +0900'
category: CS231n
use_math: true
---

## 1. Optimization(최적화)

-   CS231n의 [유튜브 강의 내용](https://youtu.be/h7iBpEHGVNc)과 [강의 노트](https://cs231n.github.io/optimization-1/)를 참고하여 작성하였습니다.
-   이 포스트는 CS231n - Lecture3 의 내용을 포함합니다.
-   데스크탑이나 노트북의 경우 글꼴 크기를 확대(ctrl + 마우스 스크롤) 하여 보는 것을 추천합니다.
-   이 글에는 **파이썬 코드가 포함**됩니다.



### 1-1. Introduction

---

- 저번시간에 배웠던 두 가지 키 포인트를 기억하자
  1. **Score function**: 이미지의 픽셀 값들을 클래스 점수로 매핑해 주는 함수
  2. **Loss function**: 모델의 parameter들이 얼마나 좋은 성능을 내는가(얼마나 정답 label과 유사한 예측을 내 놓는가)에 대해 알려주는 함수


- **full SVM loss**

$$
L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + 1) \right] + \alpha R(W)
$$

- 이제 위의 내용을 바탕으로 마지막 요소인 **Optimization(최적화)**에 대해서 알아보자.
  - 최적화는 손실 함수의 값이 최소가 되도록 하는 가중치 **W**를 조절하는 과정이다.



### 1-2. Visualizing the loss function

---
- 손실 함수를 어떻게 시각화 할 것인지에 대한 내용이다.
- **CIFAR-10 (이미지 데이터 셋)**을 기억해보자, 우리는 이 데이터 셋을 training 시킬 때 가중치 **W**의 크기를 [10 x 3073]으로 두고 하였다. 그런데 이는 시각화 하기 어렵다. 최대 3차원 까지만 시각화가 가능하기 때문이다.
- 따라서, 이러한 고차원 상의 점들을 시각화 하기 위해 1차원(직선)이나 2차원(평면)으로 잘라서 보는 아이디어가 등장했다. 하나씩 살펴보자
- **1차원(직선)**
  - 먼저 가중치 행렬 **W**를 무작위로 하나 뽑고 이를 **W<sub>1</sub>**이라 하겠다.
  - 그렇다면 손실 함수는  **L(W + aW<sub>1</sub>)**와 같은 형태로 나타날 것이다.
    - 기존의 가중치 행렬 **W**가 있고, **W<sub>1</sub>**의 방향으로 **a**만큼 이동시키는 것.
    - **a**값이 x축, 손실 함수 값이 y축에 나타난다.
- **2차원(평면)**
  - 여기서도 가중치 행렬 **W**를 무작위로 하나더 뽑고 이를 **W<sub>2</sub>**라 하겠다.
  - 그렇다면 손실 함수는  **L(W + aW<sub>1</sub> + bW<sub>2</sub>)**와 같은 형태로 나타날 것이다.
    - **a,b** 값에 따라 **W<sub>1</sub>, W<sub>2</sub>**방향으로 움직이는 것 (a,b는 각각 x, y 축에 해당한다.)
- 그림으로 한번에 나타내면 아래와 같다.

![svmloss1_2d](\assets\images\cs231n\svmloss1_2d.PNG)

- 첫 번째 사진(왼쪽)은 1차원 상에서 a 값이 변화함에 따라 loss function 값의 변화를 보여주는 것이고
- 나머지 두개는 2차원 평면 상에서 a,b 값의 변화에 따른 loss function 값을 보여준다.
  - 파란색이 낮은 손실, 빨간색이 높은 손실을 의미한다.


- 첫 번째 사진을 자세히 보자, 그러면 **부분적으로 선형(piecewise linear)**임을 알 수 있다.
  - **Linearlity는 f(aX + bY) = af(X) + bf(Y)**로 나타난 다는 것을 기억하자(선형대수)
- 이렇게 부분적으로 선형이 나타나는 이유를 손실 함수의 수식으로 설명할 수 있다.

$$
L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + 1) \right]
$$

- 위의 식에서도 알 수 있듯이 data loss L<sub>i</sub>는 **W**의 선형함수들의 합으로 표현된다.
  - **W**의 선형함수는 **f(x<sub>i</sub>; W)<sub>j</sub>**꼴로 나타났던 것을 기억하자.
- 더 명확히 표현하기 위해 데이터 셋이 3개의 1차원 상의 점들과 3개의 클래스로 구성됬다고 하자,<br>규제가 없다고 했을 때 총 SVM loss는 아래와 같이 나타난다.

$$
% <![CDATA[
\begin{align}
L_0 = & \max(0, w_1^Tx_0 - w_0^Tx_0 + 1) + \max(0, w_2^Tx_0 - w_0^Tx_0 + 1) \\\\
L_1 = & \max(0, w_0^Tx_1 - w_1^Tx_1 + 1) + \max(0, w_2^Tx_1 - w_1^Tx_1 + 1) \\\\
L_2 = & \max(0, w_0^Tx_2 - w_2^Tx_2 + 1) + \max(0, w_1^Tx_2 - w_2^Tx_2 + 1) \\\\
L = & (L_0 + L_1 + L_2)/3
\end{align} %]]>
$$

- 여기서 **w<sub>j</sub>와 x**는 실제로 1차원[1 x 1]이기 때문에 **w**를 전치(transpose)해주지 않아도 똑같은 의미가 된다.
  - x는 1차원 상의 점이라고 가정하였고, 가중치 **W**는 3개의 클래스를 구분해야 하기 때문에 [3 x 1] 행렬이 되는데, 여기서 **w<sub>j</sub>**는 행 하나를 뽑은것이기 때문에 [1 x 1]이 된다.
- 위의 식에서 **w<sub>0</sub>**를 보면 max(0, -) 내에 속해있기 때문에 0을 기준으로 꺾인다는 것을 예상할 수 있다.
  - 실제 시각화한 그림은 아래와 같다.
   ![svmbowl](\assets\images\cs231n\svmbowl.png)
  - x축은 가중치 혹은 parameter이고, y축은 loss 값이다.
  - 선들을 보면 **max(0, - )**의 특성상 0(loss값)을 기준으로 꺾인다는 것을 확인 할 수 있다.
  - 서로 다른 3가지 색의 loss(L<sub>1</sub>, L<sub>2</sub>, L<sub>3</sub>)를 합치면 오른쪽의 아래로 볼록한 그래프가 생기는 것을 확인 할 수 있다.
  - 이런 개형의 함수를 볼록 함수(convex function)이라고 한다.
  - 이 score function을 neural networks로 확장시키면 더이상 볼록 함수의 형태가 아니라 울퉁불퉁하고 복잡한 형태를 띈다고 한다.
- **미분 불가능한 손실 함수**의 경우도 살펴보자
  - 위의 그래프에서도 볼 수 있듯이 max(0, -)의 특성상 0이 되는 지점에서 미분이 불가능해진다.
  - 따라서 이 지점에서 gradient 값이 존재하지 않아 subgradient를 사용한다고 한다.
  - 강의 노트에서는 앞으로 gradient = subgradient라고 생각하면 된다고 한다.



## 2. Optimization

- 이제 이 글의 주제인 최적화에 대해 다뤄보자
- 시작하기 전에 최적화의 목적을 다시한번 상기하자.

  > The goal of optimization is to find **W** that minimizes the loss function.

- 강의 노트에서는 이 section 에서는 주로 볼록 함수(convex function) 형태를 다루기 때문에 나중에 신경망의 최적화를 할 때는 여기서 나온 방법을 적용하기 어렵다는 것을 알아두라고 한다.



### 2-1. [Strategy #1] A first very bad idea solution: Random search

---
- 어떻게 모델의 가중치 **W**를 최적화 할 수 있을까?
- 가장 간단하게는 무작위로 **W** 값을 넣어보며 성능이 좋은것을 찾으면 된다!
- 실제로 10개의 클래스를 구분해야 하는 분류기에 무작위 방법으로 정한 **W**를 적용시키고 test set에 넣어보면 **15.5%**의 정확도가 나온다고 한다. (그냥 찍는게 10%니 이것보다는 좋다...)
- 이처럼 무작위로 계속 **W**값을 넣어보면서 찾으면 실제 성능이 나쁘게 나올 뿐만 아니라 복잡한 신경망의 경우는 경우의수가 많아서 시간적으로도 비효율적이다.

- 따라서 **iterative refinement**방식이 고안되었다.
  - 처음에 **W**를 무작위로 뽑고서 더 좋은 성능을 내도록 조금씩 개선시키는 것이다.

    > **Our strategy will be start with random weights and iteratively refine them over time to get lower loss**

  - 강의 노트에서는 **눈을 가리고 하산** 하는것에 비유했다.
  - 여기서 loss 값은 고도가 된다.
  - 매 위치에서 한발짝 움직였을때 고도가 낮아지는 지점을 찾아 계속 이동하다보면 결국 평지에 도착할 것이라는 얘기다.



### 2-2. [Strategy #2] Random Local Search

---
- 이제 앞에서 설명한 것을 구체적으로 알아보자.
  - 매 위치에서 한발짝 움직였을때 고도가 낮아지는 지점을 찾는것
- 처음에 무작위로 **W**하나를 뽑는다.
- 그리고 임의의 방향을 나타내는 δ**W**를 뽑는다. (여러 방향으로 발을 짚어보는것)
- 만약 **W** + δ**W**가 loss를 낮춘다면, **W**를 **W** + δ**W**로 업데이트 해준다.
  - 이런 방식으로 진행했을 때, test set을 넣어서 평가해보면 **21.4%**의 정확도를 보여준다고 한다.
  - 앞의 15.5% 보다는 성능이 좋아졌지만 이거를 실제로 사용하기에는 부족하고, 또한 계산량도 많다고 한다. 



### 2-3. [Strategy #3] Following the Gradient

---
- 전략 2에서 **W** + δ**W**와 같이 무작위로 방향을 업데이트 하던 것을 생각해보자
- 실제로는 δ**W** 처럼 무작위로 방향을 설정할 필요가 없다
- 왜나하면, **gradient**가 있기 때문이다.
  - 다시 말하면, loss function의 gradient 방향으로 업데이트 해주면 되기 때문
- 아까 하산의 비유로 치자면 한 지점에서 발을 디뎠을때, 가장 가파르게 고도가 감소하는 지점으로 발을 디딛는 것이다.
- 일차원 함수(one-dimensional functions)를 생각해보자
  - 일차원 함수에서 경사(slope)는 각 지점에서의 순간 기울기를 나타낸다.
  - **gradient**는 이 순간 기울기를 변수가 하나가 아닌 여러개인 경우로 일반화(generalization)시킨 것이다.
  - 즉, gradient는 입력 공간(input space)의 각 차원에 해당하는 기울기들의 벡터인 것이다.
- 함수가 숫자 하나가 아니라 벡터를 입력으로 받게 되면, 미분을 편미분이라고 부르고<br>gradient는 각 차원으로의 편미분들을 모아놓은 벡터이다.

  ![gradient13](\assets\images\cs231n\gradient13.PNG)

  - 수식으로 보면 위처럼 각 차원으로의 편미분들을 열벡터 형태로 모아놓은 것이 gradient이다.



## 3. Computing the gradient
- 방금 전까지 gradient를 이용해서 최적화(optimization)을 수행한다는 것을 배웠다.
- 그럼 지금부터는 이 gradient를 어떻게 계산하는지에 대해 배울 것이다.
- CS231n 강의를 보면 **numerical gradient**를 보여주며 이는 매우 비효율적이고,<br>살짝 오류가 있지만 계산 속도가 빠른 **analytic gradient**를 사용한다는 말이 나온다.



### 3-1. Computing the gradient numerically with finite differences
---
- 여기서는 강의노트에 파이썬 코드를 사용해 설명을 하고 있어 **부득이하게 파이썬 코드를 추가한다.**
- **3-1의 내용의 경우 [이곳](http://aikorea.org/cs231n/optimization-1/)의 해석을 가져왔다.**

```python
def eval_numerical_gradient(f, x):

# 함수 f의 x에서의 그라디언트를 매우 단순하게 구현하기.
#  - f 는 입력값 1개를 받는 함수여야한다.
#  - x는 numpy 어레이(array)로서그라디언트를 계산할 지점 (역자 주: 그라디언트는 당연하게도 어디서 계산하느냐에 따라 달라지므로, 함수 f 뿐 아니라 x도 정해줘야함).

  fx = f(x) # 원래 지점 x에서 함수값 구하기.
  grad = np.zeros(x.shape)
  h = 0.00001

  # x의 모든 인덱스를 다 돌면서 계산하기.
  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
  while not it.finished:

    # 함수 값을  x+h에서 계산하기.
    ix = it.multi_index
    old_value = x[ix]
    x[ix] = old_value + h # 변화랑h
    fxh = f(x) # evalute f(x + h)
    x[ix] = old_value # 이전 값을 다시 가져온다. (매우 중요!)

    # 편미분 계산
    grad[ix] = (fxh - fx) / h # 기울기
    it.iternext() # 다음 단계로 가서 반복.

  return grad
```
- 위의 코드는, 위에 주어진 그라디언트(gradient) 식을 이용해서 모든 차원을 하나씩 돌아가면서 그 방향으로 작은 변화 **h**를 줬을 때, 손실함수(loss function)의 값이 얼마나 변하는지를 구해서, 그 방향의 편미분 값을 계산한다.<br>변수 **grad**에 전체 그라디언트(gradient) 값이 최종적으로 저장된다.

- **실제 고려할 사항**<br>h가 0으로 수렴할 때의 극한값이 그라디언트(gradient)의 수학적으로 정의인데, (이 예시에서 나온 것처럼 1e-5 같이) 작은 값이면 충분하다. 이상적으로, 수치적인 문제를 일으키지 않는 수준에서 가장 작은 값을 쓰면 된다. 덧붙여서, 실제 활용할 때, x를 양 방향으로 변화를 주어서 구한 수식이 더 좋은 경우가 많다.

$$
\frac{f(x+h) - f(x-h)}{2h}
$$

- 위에서 계산한 함수를 이용하면, 아무 함수의 아무 값에서나 그라디언트(gradient)를 계산할 수 있다. 무작위로 뽑은 파라미터(parameter/weight)값에서 CIFAR-10의 손실함수(loss function)의 그라디언트를 구해본다.

```python
# 위의 범용코드를 쓰려면 함수가 입력값 하나(이 경우 파라미터)를 받아야함.
# 따라서X_train와 Y_train은 입력값으로 안 치고 W 하나만 입력값으로 받도록 함수 다시 정의.
def CIFAR10_loss_fun(W):
  return L(X_train, Y_train, W)

W = np.random.rand(10, 3073) * 0.001 # 랜덤 파라미터 벡터.
df = eval_numerical_gradient(CIFAR10_loss_fun, W) # 그라디언트를 구했다.
```

- 그라디언트(gradient)는 각 차원에서 **CIFAR-10**의 손실함수(loss function)의 기울기를 알려주는데, 그걸 이용해서 파라미터(parameter/weight)를 업데이트한다.


```python
loss_original = CIFAR10_loss_fun(W) # 기존 손실값
print 'original loss: %f' % (loss_original, )

# 스텝크기가 주는 영향에 대해 알아보자.
for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:
  step_size = 10 ** step_size_log
  W_new = W - step_size * df # 파라미터(parameter/weight) 공간 상의 새 파라미터 값
  loss_new = CIFAR10_loss_fun(W_new)
  print 'for step size %f new loss: %f' % (step_size, loss_new)

# prints:
# original loss: 2.200718
# for step size 1.000000e-10 new loss: 2.200652
# for step size 1.000000e-09 new loss: 2.200057
# for step size 1.000000e-08 new loss: 2.194116
# for step size 1.000000e-07 new loss: 2.135493
# for step size 1.000000e-06 new loss: 1.647802
# for step size 1.000000e-05 new loss: 2.844355
# for step size 1.000000e-04 new loss: 25.558142
# for step size 1.000000e-03 new loss: 254.086573
# for step size 1.000000e-02 new loss: 2539.370888
# for step size 1.000000e-01 new loss: 25392.214036
```


- **Update in negative gradient direction.**<br>위 코드에서, 새로운 파라미터 **W_new**로 업데이트할 때, 그라디언트(gradient) **df**의 반대방향으로 움직인 것을 주목하자. 왜냐하면 우리가 원하는 것은 손실함수(loss function)의 증가가 아니라 감소하는 것이기 때문이다.

- **Effect of step size**<br>그라디언트(gradient)에서 알 수 있는 것은 함수값이 가장 빠르게 증가하는 방향이고, 그 방향으로 대체 얼만큼을 가야하는지는 알려주지 않는다. 강의 뒤에서 다루게 되겠지만, 얼만큼 가야하는지를 의미하는 스텝 크기(혹은 학습 속도라고도 함)는 신경망(neural network)를 학습시킬 때 있어 가장 중요한 (그래서 결정하기 까다로운) hyperparameter가 될 것이다. 눈 가리고 하산하는 비유에서, 우리는 우리 발 밑으로 어느 방향이 가장 가파른지 느끼지만, 얼마나 발을 뻗어야할 지는 불확실하다. 발을 살살 휘져으면, 꾸준하지만 매우 조금씩밖에 못 내려갈 것이다. (이는 아주 작은 스텝 크기에 비견된다.) 반대로, 욕심껏 빨리 내려가려고 크고 과감하게 발을 내딛을 수도 있는데, 항상 뜻대로 되지는 않을지 모른다.<br>위의 제시된 코드에서와 같이, **어느 수준 이상의 큰 스텝 크기는 오히려 손실값을 증가시킨다.**

- **스텝(step) 크기의 위험성**

  ![stepsize](\assets\images\cs231n\stepsize.jpg)

  - 위의 사진에서 하얀색 방향이 가장 빠르게 loss를 감소시키는 방향이다.
  - 그러나 step크기를 너무 크게 잡는다면 파란색 지역에 도착하더라도 학습이 계속 진행되어 결국 loss 값이 커지는 지점에 도착할 것이다.
    - 이 말은 빠르게 학습이 진행되도록 하면 그 만큼의 위험성(모델의 성능저하)을 가지고 간다는 의미이다.
  - 따라서, **스텝 크기는 매우 중요한 hyperparameter**이고 조심스럽게 설정해야한다.

   
- **A problem of efficiency**
- gradient를 수치적으로 계산하는 것은 알다시피 parameter의 수에 따라 선형적으로 늘어난다.
- **CIFAR-10** 데이터 셋을 사용하는 경우를 예시로 들면 이때는 가중치 **W**의 크기가 [10x3072] 이고 여기서 bias 한개를 더하면 총 30,721번 손실 함수 값을 계산해서 gradient를 구해야 한다.
- 한번의 가중치 업데이트를 위해 30,721번 계산해야 한다는 것은 매우 비효율적이어서 더 좋은 방법을 생각해봐야 할 것이다.



### 3-2. Computing the gradient analytically with Calculus

---
- 3-1에서는 numerical gradient를 사용하였다.
- numerical gradient는 유한한 차이 **h**를 이용하기 때문에 우리가 볼 때 매우 단순하기 때문이다.
- 하지만, 문제가 발생한다.
  - 실제 기울기 계산 과정을 보면 limit을 붙여서 **h**를 0으로 보내는데, numerical gradient에서는 그냥 0에 근사한 **h** 값을 사용하기 때문에 계산이 비효율적이라는 것이다.
- 따라서 미적분학을 이용하여 **analytically하게 gradient를 계산**하는 방법이 고안되었다.
- 이 방식을 사용하면 정확한 수식(direct formula)를 사용하기 때문에 계산이 빠르다는 것이다.
- 하지만, numerical한 방식보다 analytically한 방식을 구현할 실수하는 경우가 많아서,<br>실제로는 analytically 한 방식으로 구현한다음, numerical 한 방식으로 구한 것과 비교해서 틀린 것이 있으면 고치는 방법을 사용한다고 한다. 이를 **gradient check**라고 부른다.


- 이제 **SVM loss**를 이용하여 예시를 들어보겠다. (data loss 부분만)

$$
L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]
$$

- 이제 이 함수를 가중치 **W**에 대해 미분하면 아래와 같은 수식을 얻는다.

$$
\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) \right) x_i
$$

- 여기서 **1**은 **정의 함수(indicator function)**라고 하는데 **1**안의 조건이 참이면 1, 거짓이면 0의 값을 갖는 함수이다.
- 수식을 처음 보면 매우 복잡해 보이지만 실제 의미는 간단하다.
  - **손실 함수의 증가에 일조하는 클래스의 개수**를 세고
  - **이를 입력 데이터 x<sub>i</sub>(vector)에 곱한것이 gradient**가 된다는 의미이다.
- 위의 gradient 식은 정답 클래스 y<sub>i</sub>에 대한 것이고, 다른 클래스 j에 대한 식은 아래와 같다.
  - **j != y<sub>i</sub>**

$$
\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i
$$

- 이렇게 gradient 수식을 구했다면, 나머지 과정들은 쉽다고 한다.


## 4. Gradient Descent
- 이제 앞에서 배운것을 총 정리하는 과정이다.
- gradient를 계속해서 계산하고, 이를 바탕으로 parameter(가중치)를 업데이트 하는 과정을 수행하는 것을 **gradient Descent(경사 하강법)**이라고 한다.
- 이것의 **vanilla** 버전은 아래와 같다고 한다.
  - vanilla는 아무것도 하지 않은 순정상태라는 의미이다.

```python
# 단순한 경사하강(gradient descent)

while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # 파라미터 업데이트(parameter update)
```

- 실제로 이러한 simple loop가 모든 신경망의 중요한 부분이라고 한다.
  > This simple loop is that at the core of all Neural Network libraries.
  
- 다른 최적화 방법들도 많지만, 그 중에서도 이 경사 하강법이 신경망을 최적화 하는데 가장 일반적으로 쓰인다고 한다.
- 앞으로 이 vanilla 버전에 여러가지를 덧붙이면서 확장시켜나간다고 한다.
  - 하지만, 어떤 방법으로 확장시키던지간에 우리가 만족할 때까지 gradient를 따라 움직인다는 idea는 유지된다는 것을 기억해야 한다. 



### 4-1. Mini-batch gradient descent.
---
- 매우 큰 규모의 어플리케이션의 경우는 training set의 크기가 수백만개 이상이 될 수 있다고 한다.
- 이런 상황에서는 한번의 parameter 업데이트를 위해 수백만번의 계산을 하는 것은 매우 비효율적인 것을 알 수 있다.
- 그래서 나온것이 **Mini-batch gradient descent**이다.
- **training set에서 일부만 뽑아 parameter 업데이트를 실행**하는 것이다.
  - ConvNets을 쓰는 경우 한 번에 120만 개 전체 데이터 중에서 256개 만을 뽑아(이를 batch라고 함) gradient를 구하고, parameter 업데이트를 실시한다.
- 파이썬 코드는 아래와 같다.

```python
# 단순한 미니배치 (minibatch) 그래디언트(gradient) 업데이트

while True:
  data_batch = sample_training_data(data, 256) # 예제 256개짜리 미니배치(mini-batch)
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # 파라미터 업데이트(parameter update)
```

- 아까 vanilla 버전에서 한 줄의 코드가 추가된것을 확인할 수 있다.
- 이렇게 전체 training set에서 batch를 뽑아 경사하강법을 실행하는 것이 잘 작동하는 이유는 training data들이 서로 연관되어있기 때문이다.


- 120만개의 이미지들로 구성된 ILSVRC이 사실 1천개의 복사본이라는 극단적인 경우를 생각하면,<br>한 이미지가 1200번 복사된 것이므로, 1200개의 이미지들의 gradient 값은 동일할 것이다.
- 그렇다면 전체 120만개를 평균내서 loss값을 구하는 것이나, 서로 다른 1천개의 이미지들을 평균내서 loss값을 구한 것이 똑같아진다.
- 실제로는 이렇게 중복된 데이터가 주어지지는 않지만 batch를 뽑을 때 전체 training set의 유사한 분포를 가지게 뽑는다면 전체 training set을 쓰는 것과 유사한 효과를 낼 것이다.
  - 모집단을 잘 대변하는 batch를 뽑는다는 의미로 해석하면 쉽다.
- 실제로, mini-batch방식을 쓰면 전체 training set을 한번에 계산하는 것보다 parameter 업데이트가 더 많이 일어나기 때문에 더 빠른 속도로 수렴(학습 속도가 빠름)한다고 한다.


- 매우 극단적인 경우에는 mini-batch 사이즈를 1로 두는 것이다.
- 이런 경우를 특별히 **Stochastic Gradient Descent(SGD)**라고 부른다.
- SGD의 경우는 계산속도가 느리기 때문에 보편적으로 사용되지는 않는다고 한다.


- **mini-batch**도 hyperparameter이기 때문에 cross-validation을 통해 우리가 최적의 값을 찾아야 하지만, 일반적으로 **컴퓨터 메모리 크기의 한계나 2의 제곱수(32, 64 or 256 등)로 결정**한다고 한다.
  - 2의 제곱수로 정하는 이유는 벡터 연산이 입력의 크기가 2의 제곱수 형태로 들어왔을 때 빠르기 때문이라고 한다.




## 5. 글을 마치며


![dataflow](\assets\images\cs231n\dataflow.jpeg)

- 오늘 배운 내용을 한번에 정리하면 위의 사진과 같다.
- 먼저 data set이 **(x<sub>i</sub>, y<sub>i</sub>)**의 고정된 형태로 주어진다.
  - x<sub>i</sub> 는 데이터, y<sub>i</sub> 는 정답(label). 
- 그다음에는 무작위로 **W**값을 초기화 한다.
- 이제 score function에 **x<sub>i</sub>**와 **W**값을 넣어 각 클래스의 점수를 계산한다.
- 그러면 손실 함수가 score function의 결과와 **y<sub>i</sub>**를 비교하여 loss 값을 계산한다.
- 그 이후에, 경사 하강법을 통해 손실 함수의 gradient를 계산하고 가중치 **W**를 업데이트 한다.
- 위의 과정을 우리가 만족할때 까지 반복한다음 test set을 넣어 최종 성능을 평가한다.



- 다음 글에서는 **오차 역전파**에 대해 다뤄볼 예정이다.